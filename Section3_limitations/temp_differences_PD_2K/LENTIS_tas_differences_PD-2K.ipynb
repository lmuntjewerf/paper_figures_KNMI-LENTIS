{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f36426-1186-426d-8804-06ab54360b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d94ee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxmean(da): \n",
    "    \"\"\"\n",
    "    Compute spatial weighted mean\n",
    "    da      :  xarray DataArray\n",
    "    \"\"\" \n",
    "    #weights = np.cos(np.deg2rad(da.lat)) \n",
    "    #weights.name = 'weights' \n",
    "    #boxmean = da.weighted(weights).mean(dim=('lat','lon')) \n",
    "    \n",
    "    if hasattr(da, 'lat'):\n",
    "        weights = np.cos(da.lat * np.pi / 180)\n",
    "        boxmean = da.weighted(weights).mean(dim=('lat','lon')) \n",
    "    elif hasattr(da, 'latitude'):\n",
    "        weights = np.cos(da.latitude * np.pi / 180)\n",
    "        boxmean = da.weighted(weights).mean(dim=('latitude','longitude')) \n",
    "    \n",
    "    return boxmean \n",
    "\n",
    "def NHboxmean(da): \n",
    "    \"\"\"\n",
    "    Compute spatial weighted mean for northern hemispere\n",
    "    da      :  xarray DataArray\n",
    "    \"\"\"\n",
    "    if hasattr(da, 'lat'): \n",
    "        weights = np.cos(da.lat * np.pi / 180)\n",
    "        boxmean = da.sel(lat=slice(0,90)).weighted(weights).mean(dim=('lat','lon')) \n",
    "    elif hasattr(da, 'latitude'):\n",
    "        weights = np.cos(da.latitude * np.pi / 180)\n",
    "        boxmean = da.sel(latitude=slice(0,90)).weighted(weights).mean(dim=('latitude','longitude')) \n",
    "    \n",
    "    return boxmean \n",
    "\n",
    "def EUboxmean(da): \n",
    "    \"\"\"\n",
    "    Compute spatial weighted mean for europe\n",
    "    da      :  xarray DataArray\n",
    "    \"\"\" \n",
    "    #weights = np.cos(np.deg2rad(da.lat)) \n",
    "    #weights.name = 'weights' \n",
    "    #boxmean = da.weighted(weights).mean(dim=('lat','lon')) \n",
    "    \n",
    "    if hasattr(da, 'lat'):\n",
    "        weights = np.cos(da.lat * np.pi / 180)\n",
    "        boxmean = da.sel(lat=slice(30,70),lon=slice(-10,40)).weighted(weights).mean(dim=('lat','lon')) \n",
    "    elif hasattr(da, 'latitude'):\n",
    "        weights = np.cos(da.latitude * np.pi / 180)\n",
    "        boxmean = da.sel(latitude=slice(30,70),longitude=slice(-10,40)).weighted(weights).mean(dim=('latitude','longitude')) \n",
    "    \n",
    "    return boxmean \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355dbe4c-b3ff-4955-b9de-dfc6c3786be4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Open the data from LENTIS PD and from 2K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ece4a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tas_PD=xr.open_mfdataset('/usr/people/muntjewe/nobackup/nobackup_1/LENTIS/PD/Amon/tas/tas*.nc',combine='nested',concat_dim='ens')\n",
    "tas_PD=ds_tas_PD['tas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "155c3fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tas_2K=xr.open_mfdataset('/usr/people/muntjewe/nobackup/nobackup_1/LENTIS/2K/Amon/tas/tas*.nc',combine='nested',concat_dim='ens')\n",
    "tas_2K=ds_tas_2K['tas']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eecc4b",
   "metadata": {},
   "source": [
    "# align the time dimension, necessary for subtracting 2 xarray datasets\n",
    "to check if it worked, run the following (this should not give an error): \n",
    "`xr.align(tas_PD, tas_2K, join='exact')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "079ebcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_2K['time'] = tas_PD['time']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48afcf1",
   "metadata": {},
   "source": [
    "### compute and print seasonal mean and std dev of the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc6ace42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "diff_season = tas_2K - tas_PD \n",
    "diff_mean = diff_season.mean(dim='ens').groupby('time.season').mean(dim='time')\n",
    "diff_std = diff_season.std(dim='ens').groupby('time.season').mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d93cabaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we are computing some statistics of the tas differences between PD an 2K (takes a long time!!\n",
      "Global\n",
      "DJF = 2.02 (ens stddev: 1.51)\n",
      "JJA = 1.9 (ens stddev: 1.23)\n",
      "MAM = 1.83 (ens stddev: 1.39)\n",
      "SON = 2.06 (ens stddev: 1.26)\n",
      "ANN = 1.95 (ens stddev: 1.35)\n",
      "\n",
      "Northern Hemisphere\n",
      "DJF = 2.67 (ens stddev: 1.99)\n",
      "JJA = 2.42 (ens stddev: 1.37)\n",
      "MAM = 2.29 (ens stddev: 1.72)\n",
      "SON = 2.72 (ens stddev: 1.49)\n",
      "== ANN: 2.52 (ens stddev: 1.64)\n",
      "\n",
      "Europe\n",
      "DJF = 2.4 (ens stddev: 2.58)\n",
      "JJA = 2.81 (ens stddev: 1.86)\n",
      "MAM = 2.29 (ens stddev: 2.16)\n",
      "SON = 2.69 (ens stddev: 1.9)\n",
      "== ANN: 2.55 (ens stddev: 2.13)\n"
     ]
    }
   ],
   "source": [
    "print('Now we are computing some statistics of the tas differences between PD an 2K (takes a long time!!')\n",
    "\n",
    "\n",
    "\n",
    "print('Global')\n",
    "## Explicit conversion by wrapping a DataArray with np.asarray also works. I need to do this to access values. See https://docs.xarray.dev/en/v0.9.3/dask.html\n",
    "glbias = (np.asarray(boxmean(diff_mean))) \n",
    "glstd = (np.asarray(boxmean(diff_std))) \n",
    "print(str(boxmean(diff_mean).season[0].values)+' = '+str(np.round(glbias[0],2))+' (ens stddev: '+str(np.round(glstd[0],2))+')')\n",
    "print(str(boxmean(diff_mean).season[1].values)+' = '+str(np.round(glbias[1],2))+' (ens stddev: '+str(np.round(glstd[1],2))+')')\n",
    "print(str(boxmean(diff_mean).season[2].values)+' = '+str(np.round(glbias[2],2))+' (ens stddev: '+str(np.round(glstd[2],2))+')')\n",
    "print(str(boxmean(diff_mean).season[3].values)+' = '+str(np.round(glbias[3],2))+' (ens stddev: '+str(np.round(glstd[3],2))+')')\n",
    "print('ANN = '+str(np.round(glbias.mean(),2))+' (ens stddev: '+str(np.round(glstd.mean(),2))+')')\n",
    "print('')\n",
    "nhbias = (np.asarray(NHboxmean(diff_mean))) \n",
    "nhstd = (np.asarray(NHboxmean(diff_std))) \n",
    "print('Northern Hemisphere')\n",
    "print(str(boxmean(diff_mean).season[0].values)+' = '+str(np.round(nhbias[0],2))+' (ens stddev: '+str(np.round(nhstd[0],2))+')')\n",
    "print(str(boxmean(diff_mean).season[1].values)+' = '+str(np.round(nhbias[1],2))+' (ens stddev: '+str(np.round(nhstd[1],2))+')')\n",
    "print(str(boxmean(diff_mean).season[2].values)+' = '+str(np.round(nhbias[2],2))+' (ens stddev: '+str(np.round(nhstd[2],2))+')')\n",
    "print(str(boxmean(diff_mean).season[3].values)+' = '+str(np.round(nhbias[3],2))+' (ens stddev: '+str(np.round(nhstd[3],2))+')')\n",
    "print('== ANN: '+str(np.round(nhbias.mean(),2))+' (ens stddev: '+str(np.round(nhstd.mean(),2))+')')\n",
    "print('')\n",
    "eubias = (np.asarray(EUboxmean(diff_mean))) \n",
    "eustd = (np.asarray(EUboxmean(diff_std))) \n",
    "print('Europe')\n",
    "print(str(boxmean(diff_mean).season[0].values)+' = '+str(np.round(eubias[0],2))+' (ens stddev: '+str(np.round(eustd[0],2))+')')\n",
    "print(str(boxmean(diff_mean).season[1].values)+' = '+str(np.round(eubias[1],2))+' (ens stddev: '+str(np.round(eustd[1],2))+')')\n",
    "print(str(boxmean(diff_mean).season[2].values)+' = '+str(np.round(eubias[2],2))+' (ens stddev: '+str(np.round(eustd[2],2))+')')\n",
    "print(str(boxmean(diff_mean).season[3].values)+' = '+str(np.round(eubias[3],2))+' (ens stddev: '+str(np.round(eustd[3],2))+')')\n",
    "print('== ANN: '+str(np.round(eubias.mean(),2))+' (ens stddev: '+str(np.round(eustd.mean(),2))+')')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ecf84d",
   "metadata": {},
   "source": [
    "### for checking purposes\n",
    "\n",
    "Also compute and print the absolute values of seasonal mean and std dev of the PD and the 2K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c90df3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_PD_season = tas_PD \n",
    "tas_PD_mean = tas_PD_season.mean(dim='ens').groupby('time.season').mean(dim='time')\n",
    "tas_PD_std = tas_PD_season.std(dim='ens').groupby('time.season').mean(dim='time')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ead3d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we are computing some statistics of the tas PD (takes a long time!!\n",
      "Global\n",
      "DJF = 287.08 (ens stddev: 1.1)\n",
      "JJA = 290.78 (ens stddev: 0.88)\n",
      "MAM = 288.8 (ens stddev: 1.0)\n",
      "SON = 289.0 (ens stddev: 0.93)\n",
      "ANN = 288.91 (ens stddev: 0.97)\n",
      "\n",
      "Northern Hemisphere\n",
      "DJF = 282.73 (ens stddev: 1.46)\n",
      "JJA = 294.57 (ens stddev: 0.97)\n",
      "MAM = 287.44 (ens stddev: 1.24)\n",
      "SON = 290.02 (ens stddev: 1.12)\n",
      "== ANN: 288.69 (ens stddev: 1.2)\n",
      "\n",
      "Europe\n",
      "DJF = 277.81 (ens stddev: 1.99)\n",
      "JJA = 293.97 (ens stddev: 1.38)\n",
      "MAM = 283.82 (ens stddev: 1.62)\n",
      "SON = 287.04 (ens stddev: 1.44)\n",
      "== ANN: 285.66 (ens stddev: 1.6)\n"
     ]
    }
   ],
   "source": [
    "print('Now we are computing some statistics of the tas PD (takes a long time!!')\n",
    "\n",
    "\n",
    "\n",
    "print('Global')\n",
    "## Explicit conversion by wrapping a DataArray with np.asarray also works. I need to do this to access values. See https://docs.xarray.dev/en/v0.9.3/dask.html\n",
    "glbias = (np.asarray(boxmean(tas_PD_mean))) \n",
    "glstd = (np.asarray(boxmean(tas_PD_std))) \n",
    "print(str(boxmean(tas_PD_mean).season[0].values)+' = '+str(np.round(glbias[0],2))+' (ens stddev: '+str(np.round(glstd[0],2))+')')\n",
    "print(str(boxmean(tas_PD_mean).season[1].values)+' = '+str(np.round(glbias[1],2))+' (ens stddev: '+str(np.round(glstd[1],2))+')')\n",
    "print(str(boxmean(tas_PD_mean).season[2].values)+' = '+str(np.round(glbias[2],2))+' (ens stddev: '+str(np.round(glstd[2],2))+')')\n",
    "print(str(boxmean(tas_PD_mean).season[3].values)+' = '+str(np.round(glbias[3],2))+' (ens stddev: '+str(np.round(glstd[3],2))+')')\n",
    "print('ANN = '+str(np.round(glbias.mean(),2))+' (ens stddev: '+str(np.round(glstd.mean(),2))+')')\n",
    "print('')\n",
    "nhbias = (np.asarray(NHboxmean(tas_PD_mean))) \n",
    "nhstd = (np.asarray(NHboxmean(tas_PD_std))) \n",
    "print('Northern Hemisphere')\n",
    "print(str(boxmean(tas_PD_mean).season[0].values)+' = '+str(np.round(nhbias[0],2))+' (ens stddev: '+str(np.round(nhstd[0],2))+')')\n",
    "print(str(boxmean(tas_PD_mean).season[1].values)+' = '+str(np.round(nhbias[1],2))+' (ens stddev: '+str(np.round(nhstd[1],2))+')')\n",
    "print(str(boxmean(tas_PD_mean).season[2].values)+' = '+str(np.round(nhbias[2],2))+' (ens stddev: '+str(np.round(nhstd[2],2))+')')\n",
    "print(str(boxmean(tas_PD_mean).season[3].values)+' = '+str(np.round(nhbias[3],2))+' (ens stddev: '+str(np.round(nhstd[3],2))+')')\n",
    "print('== ANN: '+str(np.round(nhbias.mean(),2))+' (ens stddev: '+str(np.round(nhstd.mean(),2))+')')\n",
    "print('')\n",
    "eubias = (np.asarray(EUboxmean(tas_PD_mean))) \n",
    "eustd = (np.asarray(EUboxmean(tas_PD_std))) \n",
    "print('Europe')\n",
    "print(str(boxmean(tas_PD_mean).season[0].values)+' = '+str(np.round(eubias[0],2))+' (ens stddev: '+str(np.round(eustd[0],2))+')')\n",
    "print(str(boxmean(tas_PD_mean).season[1].values)+' = '+str(np.round(eubias[1],2))+' (ens stddev: '+str(np.round(eustd[1],2))+')')\n",
    "print(str(boxmean(tas_PD_mean).season[2].values)+' = '+str(np.round(eubias[2],2))+' (ens stddev: '+str(np.round(eustd[2],2))+')')\n",
    "print(str(boxmean(tas_PD_mean).season[3].values)+' = '+str(np.round(eubias[3],2))+' (ens stddev: '+str(np.round(eustd[3],2))+')')\n",
    "print('== ANN: '+str(np.round(eubias.mean(),2))+' (ens stddev: '+str(np.round(eustd.mean(),2))+')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d468f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tas_2K_season = tas_2K\n",
    "tas_2K_mean = tas_2K_season.mean(dim='ens').groupby('time.season').mean(dim='time')\n",
    "tas_2K_std = tas_2K_season.std(dim='ens').groupby('time.season').mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "976cc5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we are computing some statistics of the tas 2K (takes a long time!!\n",
      "Global\n",
      "DJF = 289.09 (ens stddev: 1.08)\n",
      "JJA = 292.68 (ens stddev: 0.9)\n",
      "MAM = 290.63 (ens stddev: 1.01)\n",
      "SON = 291.06 (ens stddev: 0.89)\n",
      "ANN = 290.86 (ens stddev: 0.97)\n",
      "\n",
      "Northern Hemisphere\n",
      "DJF = 285.4 (ens stddev: 1.4)\n",
      "JJA = 296.99 (ens stddev: 1.01)\n",
      "MAM = 289.73 (ens stddev: 1.24)\n",
      "SON = 292.75 (ens stddev: 1.03)\n",
      "== ANN: 291.22 (ens stddev: 1.17)\n",
      "\n",
      "Europe\n",
      "DJF = 280.24 (ens stddev: 1.74)\n",
      "JJA = 296.76 (ens stddev: 1.35)\n",
      "MAM = 286.1 (ens stddev: 1.49)\n",
      "SON = 289.73 (ens stddev: 1.33)\n",
      "== ANN: 288.21 (ens stddev: 1.48)\n"
     ]
    }
   ],
   "source": [
    "print('Now we are computing some statistics of the tas 2K (takes a long time!!')\n",
    "\n",
    "\n",
    "\n",
    "print('Global')\n",
    "## Explicit conversion by wrapping a DataArray with np.asarray also works. I need to do this to access values. See https://docs.xarray.dev/en/v0.9.3/dask.html\n",
    "glbias = (np.asarray(boxmean(tas_2K_mean))) \n",
    "glstd = (np.asarray(boxmean(tas_2K_std))) \n",
    "print(str(boxmean(tas_2K_mean).season[0].values)+' = '+str(np.round(glbias[0],2))+' (ens stddev: '+str(np.round(glstd[0],2))+')')\n",
    "print(str(boxmean(tas_2K_mean).season[1].values)+' = '+str(np.round(glbias[1],2))+' (ens stddev: '+str(np.round(glstd[1],2))+')')\n",
    "print(str(boxmean(tas_2K_mean).season[2].values)+' = '+str(np.round(glbias[2],2))+' (ens stddev: '+str(np.round(glstd[2],2))+')')\n",
    "print(str(boxmean(tas_2K_mean).season[3].values)+' = '+str(np.round(glbias[3],2))+' (ens stddev: '+str(np.round(glstd[3],2))+')')\n",
    "print('ANN = '+str(np.round(glbias.mean(),2))+' (ens stddev: '+str(np.round(glstd.mean(),2))+')')\n",
    "print('')\n",
    "nhbias = (np.asarray(NHboxmean(tas_2K_mean))) \n",
    "nhstd = (np.asarray(NHboxmean(tas_2K_std))) \n",
    "print('Northern Hemisphere')\n",
    "print(str(boxmean(tas_2K_mean).season[0].values)+' = '+str(np.round(nhbias[0],2))+' (ens stddev: '+str(np.round(nhstd[0],2))+')')\n",
    "print(str(boxmean(tas_2K_mean).season[1].values)+' = '+str(np.round(nhbias[1],2))+' (ens stddev: '+str(np.round(nhstd[1],2))+')')\n",
    "print(str(boxmean(tas_2K_mean).season[2].values)+' = '+str(np.round(nhbias[2],2))+' (ens stddev: '+str(np.round(nhstd[2],2))+')')\n",
    "print(str(boxmean(tas_2K_mean).season[3].values)+' = '+str(np.round(nhbias[3],2))+' (ens stddev: '+str(np.round(nhstd[3],2))+')')\n",
    "print('== ANN: '+str(np.round(nhbias.mean(),2))+' (ens stddev: '+str(np.round(nhstd.mean(),2))+')')\n",
    "print('')\n",
    "eubias = (np.asarray(EUboxmean(tas_2K_mean))) \n",
    "eustd = (np.asarray(EUboxmean(tas_2K_std))) \n",
    "print('Europe')\n",
    "print(str(boxmean(tas_2K_mean).season[0].values)+' = '+str(np.round(eubias[0],2))+' (ens stddev: '+str(np.round(eustd[0],2))+')')\n",
    "print(str(boxmean(tas_2K_mean).season[1].values)+' = '+str(np.round(eubias[1],2))+' (ens stddev: '+str(np.round(eustd[1],2))+')')\n",
    "print(str(boxmean(tas_2K_mean).season[2].values)+' = '+str(np.round(eubias[2],2))+' (ens stddev: '+str(np.round(eustd[2],2))+')')\n",
    "print(str(boxmean(tas_2K_mean).season[3].values)+' = '+str(np.round(eubias[3],2))+' (ens stddev: '+str(np.round(eustd[3],2))+')')\n",
    "print('== ANN: '+str(np.round(eubias.mean(),2))+' (ens stddev: '+str(np.round(eustd.mean(),2))+')')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "c73f727b6fa51998c2002baea8905687ec8c32318f292fd9c6441b744c90acec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
